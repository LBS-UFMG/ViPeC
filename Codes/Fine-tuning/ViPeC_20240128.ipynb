{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![Sem t√≠tulo.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "VQ1PJ50gmIiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Federal University of Minas Gerais\n",
        "\n",
        "Department of Computer Science\n",
        "\n",
        "[Bioinformatics and Systems Laboratory](http://bioinfo.dcc.ufmg.br/)\n",
        "\n",
        "Authors: Lucas Moraes, Diego Mariano and Prof. Dr. Raquel Cardoso de Melo-Minardi"
      ],
      "metadata": {
        "id": "XSpNuFJlmWtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This source code, developed using PyTorch, aims to fine-tune the transformer model for the following specific tasks:\n",
        "(i) classifying protein-peptide interfaces based on sequence similarities; and (ii) classifying protein-peptide\n",
        "interfaces according to similarities in the peptide's role and function.. This code has been used in the academic\n",
        "and research context of the Department of Computer Science at the Federal University of Minas Gerais, specifically\n",
        "in the Bioinformatics and Systems Laboratory.\n",
        "'''"
      ],
      "metadata": {
        "id": "NNZizSwPnF2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "THiIcglEnCjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jx61xtPunSq",
        "outputId": "b9ecf11f-33a6-4791-b084-953dd0c218e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAvu2Onwu-ga"
      },
      "source": [
        "\n",
        "> Importa√ß√£o de bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2ZeB-G6yusc-",
        "outputId": "052e647c-c11d-4fb0-8f50-15a7b32182ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpiaNFwvwYE5"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Sync with Drive"
      ],
      "metadata": {
        "id": "fI2fDuBkJf1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access dataset directories and the model save path\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7kOt6QU0PUu",
        "outputId": "ac004fed-21d4-4d92-ddca-3ac7250b20d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base directory for reference\n",
        "\n",
        "BASE_DIR = \"/content/drive/My Drive/\""
      ],
      "metadata": {
        "id": "RK-ucWIA0XGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCYMn8hZwKiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa476419-839f-48ca-8fdf-7f74175184c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x18gNoC0o1g"
      },
      "source": [
        "\n",
        "> Create Datasets and DataLoaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eStUg2vNzpJl"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGmYMF_r0-8K"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF40XAlc60aX"
      },
      "outputs": [],
      "source": [
        "# Image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Patch size\n",
        "PATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZDRYRvtwJ1x"
      },
      "outputs": [],
      "source": [
        "# Define directories for training, validation, and testing datasets\n",
        "\n",
        "train_dir = '/content/drive/My Drive/Dataset/Variants/Training'\n",
        "validation_dir = '/content/drive/My Drive/Dataset/Variants/Validation'\n",
        "test_dir = '/content/drive/My Drive/Dataset/Variants/P1'\n",
        "save_dir = '/content/drive/My Drive/Models/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3bW3j5QztSI"
      },
      "outputs": [],
      "source": [
        "NUM_WORKERS = os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bPSPqoUwJoJ"
      },
      "outputs": [],
      "source": [
        "def create_data_loaders(train_dir:str, validation_dir:str, test_dir:str, batch_size:int, transform:transforms.Compose, num_workers:int=NUM_WORKERS):\n",
        "\n",
        "  \"\"\"\n",
        "    Create PyTorch data loaders for the datasets.\n",
        "\n",
        "    Parameters:\n",
        "    - train_dir: Path to the training data directory.\n",
        "    - validation_dir: Path to the validation data directory.\n",
        "    - test_dir: Path to the test data directory.\n",
        "    - batch_size: Number of images to process in a batch.\n",
        "    - transform: Image transformations to apply.\n",
        "    - num_workers: Number of subprocesses to use for data loading.\n",
        "  \"\"\"\n",
        "\n",
        "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "  train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "  validation_data = datasets.ImageFolder(validation_dir, transform=transform)\n",
        "  validation_data_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "  test_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  return train_data_loader, validation_data_loader, test_data_loader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ychg5LB8oLf"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor()\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B01RshdO9Qhr"
      },
      "outputs": [],
      "source": [
        "# Create dataloaders for the datasets\n",
        "train_dataloader, test_dataloader, class_names = create_data_loaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=transform\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the distance map"
      ],
      "metadata": {
        "id": "dtCUAJalMBeW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xSvg9V91ITf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of images\n",
        "image_batch, label_batch = next(iter(train_dataloader))\n",
        "\n",
        "# Get a single image from the batch\n",
        "image, label = image_batch[0], label_batch[0]\n",
        "\n",
        "# View the batch shapes\n",
        "print(image.shape, label)\n",
        "\n",
        "# Plot image with matplotlib\n",
        "plt.imshow(image.permute(1, 2, 0)) # rearrange image dimensions to suit matplotlib [color_channels, height, width] -> [height, width, color_channels]\n",
        "plt.title(class_names[label])\n",
        "plt.axis(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkZrg6JYq51"
      },
      "source": [
        "\n",
        "\n",
        "> Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "hf6vMFVSOgee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8Iq5OcAGG0i",
        "outputId": "9632f8d8-6ef1-439b-d684-e452b0bda4a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL1RbotXZAPA"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained model\n",
        "pretrained_weights = torchvision.models.ViT_H_14_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
        "pretrained_model = torchvision.models.vit_h_14(weights=pretrained_weights).to(device)\n",
        "for param in pretrained_model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvOv8X0sc-by",
        "outputId": "4aa4ae06-20f5-41b5-b6b5-2fa8ff3175f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[224]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BICUBIC\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "pretrained_transforms = pretrained_weights.transforms()\n",
        "print(pretrained_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD1-4Il_j_cv"
      },
      "outputs": [],
      "source": [
        "train_dataloader_pretrained, validation_dataloader_pretrained, test_dataloader_pretrained, class_names = create_data_loaders(train_dir=train_dir,\n",
        "                                                                                                                              validation_dir=validation_dir,\n",
        "                                                                                                                              test_dir=test_dir,\n",
        "                                                                                                                              transform=pretrained_transforms,\n",
        "                                                                                                                              batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfsOawXTkvbe"
      },
      "outputs": [],
      "source": [
        "# Update the classifier head of the pre-trained model\n",
        "pretrained_model.heads = nn.Sequential(nn.Linear(in_features=1280, out_features=len(class_names))).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTsHpksZaByl"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(params=pretrained_model.parameters(),\n",
        "                             lr=1E-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWjMzqRwFcqa"
      },
      "source": [
        "\n",
        "> Hyperparameter optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-6jnY50aDWD"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "greater_accuracy = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  pretrained_model.train()  # Set model to training mode\n",
        "  for i, (inputs, labels) in enumerate(train_dataloader_pretrained):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = pretrained_model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}], Loss: {loss.item():.4f}')\n",
        "\n",
        "  pretrained_model.eval()  # Set model to evaluation mode\n",
        "  with torch.no_grad():\n",
        "    correct_predictions = 0\n",
        "    total = 0\n",
        "    for inputs, labels in validation_dataloader_pretrained:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      outputs = pretrained_model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    validation_accuracy = 100 * correct_predictions / total\n",
        "    print(f'Accuracy of the model on the validation images: {validation_accuracy:.2f} %')\n",
        "\n",
        "    if validation_accuracy >= greater_accuracy:\n",
        "      greater_accuracy = validation_accuracy\n",
        "      torch.save(pretrained_model.state_dict(), os.path.join(save_dir, f\"pretrained_model_epoch{epoch+1}_acc{round(greater_accuracy)}.pth\"))\n",
        "      print(f\"Pretrained model saved with accuracy: {greater_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Fine tuning"
      ],
      "metadata": {
        "id": "bqxd0MqXcXPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "min_loss = torch.inf\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    pretrained_model.train()  # Set model to training mode\n",
        "    epoch_losses = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader_pretrained):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = pretrained_model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss = sum(epoch_losses) / len(epoch_losses)  # Calculate average loss for the epoch\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}], Average Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Save the model if the average loss of the current epoch is less than min_loss\n",
        "    if epoch_loss < min_loss:\n",
        "        print(f\"Epoch {epoch + 1}: Loss improved from {min_loss:.4f} to {epoch_loss:.4f}. Saving model...\")\n",
        "        min_loss = epoch_loss  # Update min_loss to the new lower value\n",
        "        torch.save(pretrained_model.state_dict(), os.path.join(save_dir, f\"pretrained_model_epoch{epoch + 1}_loss{epoch_loss:.4f}.pth\"))"
      ],
      "metadata": {
        "id": "gGv3iGWLJSw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(pretrained_model.state_dict(), os.path.join(save_dir, f\"vipec_20240325_sequences_propedia_v2-3_fold1.pth\"))"
      ],
      "metadata": {
        "id": "GzaL11Nbk_o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B7iwT06BR7V"
      },
      "source": [
        "\n",
        "\n",
        "> Load the saved model state dictionary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K54Z6F9StJJJ"
      },
      "outputs": [],
      "source": [
        "# Load the saved model state dictionary\n",
        "pretrained_model.load_state_dict(torch.load(os.path.join(save_dir, f\"vipec_20240325_sequences_propedia_v2-3_fold5.pth\")))\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pretrained_model = pretrained_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "pretrained_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpvsjZytNBWz"
      },
      "source": [
        "\n",
        "> Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kY5lMRXZncj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "num_classes = 5  # Classes\n",
        "\n",
        "# Initialize confusion matrix\n",
        "confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_dataloader_pretrained:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = pretrained_model(images)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # Update confusion matrix\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "        confusion_matrix[label.item(), prediction.item()] += 1\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy per class from the confusion matrix\n",
        "for i in range(num_classes):\n",
        "    correct = confusion_matrix[i, i]\n",
        "    total = confusion_matrix[i].sum()\n",
        "    if total > 0:\n",
        "        print(f'Accuracy for class {i}: {100 * correct / total:.2f}%')\n",
        "    else:\n",
        "        print(f'Class {i} has no samples')\n",
        "\n",
        "# Overall accuracy\n",
        "overall_accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
        "print(f'Overall Accuracy: {100 * overall_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "6UkxzwkE57kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(confusion_matrix):\n",
        "    num_classes = confusion_matrix.shape[0]\n",
        "    precision = np.zeros(num_classes)\n",
        "    recall = np.zeros(num_classes)\n",
        "    f1_score = np.zeros(num_classes)\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        tp = confusion_matrix[i, i]\n",
        "        fp = confusion_matrix[:, i].sum() - tp\n",
        "        fn = confusion_matrix[i, :].sum() - tp\n",
        "\n",
        "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score[i] = 2*precision[i]*recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
        "\n",
        "    # Macro average\n",
        "    macro_precision = np.mean(precision)\n",
        "    macro_recall = np.mean(recall)\n",
        "    macro_f1_score = np.mean(f1_score)\n",
        "\n",
        "    # Micro average (overall)\n",
        "    tp_total = np.trace(confusion_matrix)\n",
        "    fp_total = np.sum(confusion_matrix.sum(axis=0) - np.diag(confusion_matrix))\n",
        "    fn_total = np.sum(confusion_matrix.sum(axis=1) - np.diag(confusion_matrix))\n",
        "\n",
        "    micro_precision = tp_total / (tp_total + fp_total) if (tp_total + fp_total) > 0 else 0\n",
        "    micro_recall = tp_total / (tp_total + fn_total) if (tp_total + fn_total) > 0 else 0\n",
        "    micro_f1_score = 2*micro_precision*micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0\n",
        "\n",
        "    return macro_precision, macro_recall, macro_f1_score, micro_precision, micro_recall, micro_f1_score\n",
        "\n",
        "macro_precision, macro_recall, macro_f1_score, micro_precision, micro_recall, micro_f1_score = calculate_metrics(confusion_matrix)\n",
        "\n",
        "print(f'Macro Precision: {macro_precision:.3f}')\n",
        "print(f'Macro Recall: {macro_recall:.3f}')\n",
        "print(f'Macro F1 Score: {macro_f1_score:.3f}')\n",
        "print(f'Micro Precision: {micro_precision:.3f}')\n",
        "print(f'Micro Recall: {micro_recall:.3f}')\n",
        "print(f'Micro F1 Score: {micro_f1_score:.3f}')"
      ],
      "metadata": {
        "id": "FoySIYFrMCYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQafV3edGQmP"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}